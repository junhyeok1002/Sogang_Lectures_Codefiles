{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd49a2c",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "- Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression: https://scikit-learn.org/stable/modules/tree.html\n",
    "- Decision tree can be used to visually and explicitly represent decisions and decision making.\n",
    "- It is a basic component of random forest, one of the most powerful machine learning algorithm.\n",
    "- DT is relatively free from preprocessing data (e.g., scaling).\n",
    "    - DT는 스케일링(단위)에 영향받지 않는다\n",
    "    - 원래는 데이터들의 크기를 비슷하게 맞춰주어야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89640c9e",
   "metadata": {},
   "source": [
    "#### Advantages and disadvantages (https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052)\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "  - Simple to understand, interpret, visualize.\n",
    "  - Decision trees implicitly perform variable screening or feature selection.\n",
    "  - Can handle both numerical and categorical data.\n",
    "  - Decision trees require relatively little effort from users for data preparation.\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "  - Decision-tree learners can create over-complex trees that do not generalize the data well. This is called overfitting.\n",
    "  - Decision trees can be unstable(높은 분산) because small variations in the data might result in a completely different tree being generated. Thus, decision trees exhibit high variance, which needs to be lowered by methods like bagging and boosting. (we wil learn about this later)\n",
    "      - 디시전 트리는 너무 유연해서 오버피팅도 잘 일어나고 학습에 사용하는 data에 따라 모형이 확확바뀜(높은 분산), 즉 배깅이나 부스팅으로 에러를 낮춰주어야함\n",
    "  - Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the data set prior to fitting with the decision tree.\n",
    "      - 클래스의 밸런스가 잘 이루어지지 않을 떄 학습이 잘 일어나지지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d8cbf",
   "metadata": {},
   "source": [
    "## How decision trees work\n",
    "\n",
    "<img src=\"./img/decision_trees.PNG\" width=\"700\" height=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b554e9",
   "metadata": {},
   "source": [
    "- 위는 디시전 트리의 모형의 구조이다\n",
    "    - 스무고개를 한다고 생각하면됨\n",
    "    - 위에서부터 참이나 거짓이냐에 따라 가지지기해서 결정하고 판단하는 것임. \n",
    "    - 맨위의 판단하는 노드를 root node 그 이후로 나오는 판단하는 노드를 intermediate node, \n",
    "        각 잎사귀 처럼 달린 결과노드를 terminal node(leaf)라고 한다\n",
    "- 또한 각 노드에서 데이터를 나눌때 불순도를 체크해서 나눈다. 이떄 불순도를 계산하는 방식에는 엔트로피 계수와 지니계수를 사용하는 방식이 많이쓰인다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e83dda",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "- hyperparameters for regularization:\n",
    "  - max_depth: 결정트리의 최대 깊이, default = None ==== DT의 층의 계수\n",
    "  - min_samples_split: 분할되기 위해 노드가 가져야 하는 최소 샘플수\n",
    "  - min_samples_leaf: 리프 노프가 가지고 있어야 할 최소 샘플수\n",
    "  - min-weight_fraction_leaf: min_samples_leaf와 같지만 가중치가 부여된 전체 샘플수 대비 비율\n",
    "  - max_leaf_nodes: 리프 노드의 최대 수\n",
    "  - max_features: 각 노드에서 분할에 사용할 특성의 최대 수\n",
    "- min_으로 시작하는 매개변수를 증가시키거나 max_로 증가하는 매개변수를 감소시키면 regularization 증가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e115b",
   "metadata": {},
   "source": [
    "### The effect of hyperparameters - 1\n",
    "\n",
    "- Max_depth = 3\n",
    "<img src=\"./img/decision_trees2.PNG\" width=\"600\" height=\"600\">\n",
    "- Max_depth = 5\n",
    "<img src=\"./img/decision_trees3.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549b0f4",
   "metadata": {},
   "source": [
    "- 위의 그림은 DT를 시각화해서 보인것이다. Depth =0일때 노란색과 나머지를 나누고\n",
    "- 1일때 2일때 점점 나눠가는 방식이다. 하지만 depth가 늘어나면 오버피팅 경향이 있고 5의 경우 보면 영역을 침범했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d3350",
   "metadata": {},
   "source": [
    "### The effect of hyperparameters - 2\n",
    "\n",
    "- No restriction\n",
    "<img src=\"./img/decision_trees4.PNG\" width=\"600\" height=\"600\">\n",
    "- min_sample_leafs = 4\n",
    "<img src=\"./img/decision_trees5.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc1ff5",
   "metadata": {},
   "source": [
    "위의 경우는 leaf가 가질 수 있는 최소 샘플수를 제한한 것인데. 제한하면 비교적 깔끔하게 분류를 하는 반면, 제한하지 않으면 지저분하게 분류를 하는 것을 볼수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92e6f4",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "- Ensemble: a set of weak learners are combined to create a strong learner that obtains better performance than a single one.\n",
    "  - Bagging (bootstrap aggregating): 데이터가 주어졌을 때, 배깅 알고리즘은 무작위 추출을 통해 새로운 훈련 데이터들을 다수 생성, 각각의 데이터에 모형을 훈련시킨 후 예측 결과를 종합하여 예측치를 도출하는 알고리즘이다.\n",
    "          - bagging 알고리즘의 목적은 bias와 variance중 var를 낮추는 것에 있다. 물론 bias를 낮추어 예측정확도를 높이는 목적으로도 사용되지만 주된 목적은 var를 낮추는 것에 있음(overfit되면 예측 var가 커짐)\n",
    "  - Boosting: 여러 개의 알고리즘이 순차적으로 학습-예측을 진행, 뒤의 모형이 이전 단계의 잘못된 예측을 올바르게 예측할 수 있도록 뒤의 모형에 가중치를 부여하여 학습과 예측을 진행하는 방식이다.\n",
    "        - 그림으로 이해하면 더 좋은데, 말로설명하면 첫번째 모형에서 경계를 나누고 제대로 분류되지 못한 아웃라이어들에게 가중치를 더 부여하여서 다음 모형에서 가중치를 고려하여 또 경계를 나누고 또 아웃라이어가 생기면 가중치를 부여해서 다음모형이 더 잘 예측하도록 학습시키는 과정이다. \n",
    "        - 부스팅은 예측 정확도를 높이는 것이 목적이고 그에따라 bias를 낮추는 것이 부스팅의 가장 큰 목적이다\n",
    "    - Adaboosting (adaptive boosting)\n",
    "    - Gradient boosting\n",
    "  - Stacking\n",
    "\n",
    "- Ensemble Learning can be viewed as the wisdom of the crowd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fab47b",
   "metadata": {},
   "source": [
    "- |                                 | bagging                   |      boosting      |                stacking                |          \n",
    "- |---------------------------|:------------------:|:--------------------------------------:|:--------:|\n",
    "- | partitioning into subsets |       random       | higher weights on misclassified samples |  various |\n",
    "- | goal                      |    min. variance   |        increase predictive power       |   both   |\n",
    "- | methods                   |   random subspace  |            gradient descent            | blending |\n",
    "- | functions to combine      | (weighted) average |            weighted majority           |   logit  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392e2a5c",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "- Decision trees are known to be prone to overfitting, which increases the variance of the forecasts.\n",
    "- Random forest (RF) method was designed to produce ensemble forecasts with lower variance.\n",
    "- random forest introduces two dimensions of randomness:\n",
    "    - (1) Bootstrap aggregation: individual trees are independently trained over bootstrapped subsets of the data.\n",
    "        - 랜덤추출을해서 데이터셋들을 만든다음 각각의 셋들에 대해 DT 훈련을 시키는 것임. 그리고 그 결과들을 종합하여 예측치를 도출하는 것임\n",
    "        - 훈련되는 sample data에 대한 ramdomness를 도입을하는 것임 \n",
    "    - (2) When optimizing each node split, only a random subsample of features are used.\n",
    "        - In decision trees, predictive features tend to be placed on the upper nodes.\n",
    "        - If the features are not randomly sampled, due to this feature the decision trees will be more correlated.\n",
    "        - Thus, the effect of ensemble will decrease.\n",
    "        \n",
    "            - 즉 각각의 노드에서 사용되는 feature를 어느정도 통제하는 것으로 이해할 수 있음\n",
    "            - 특징들을 통제하지 않으면 상위노드에 강한 예측 feature가 놓이게 되는 경향이 있고 그에 따라서 decision tree들의 모형이 비슷해져서 correlated되는 경향이 있다. 랜덤포레스트 모형의 목적은 각 dt들의 결과를 종합해서 각모형들의 있는 오류를 없애는 것인데(분산을 낮추는 것). 각각의 dt들이 서로 같아져 버리면 그의미가 사라진다. 즉 그러므로 랜덤추출로 dataset을 만들고 ramdom subsample of feature를 사용한다\n",
    "            - (따라서 앙상블러닝에서 배깅알고리즘이 잘 작동하기 위해서는 여러개의 모형을 사용할때 이 모형간의 유사도를 최대한 낮춰줘야 하는 이슈도 있다.) \n",
    "            \n",
    "            \n",
    "                - 이렇게해서 정확도를 구하면 개별 DT의 정확도 보다 낮을 수는 있지만, 분산이 낮아지고 앞으로 다른 데이터를 수집하더라도 여러가지 데이터셋을 잘 예측할 수 있는 모형이된다.\n",
    "                - 분산을 낮춤으로써 과적합을 방지한다고 생각하면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ded41fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex  sibsp  parch     fare  class    who  adult_male  \\\n",
       "0         0       3    male      1      0   7.2500  Third    man        True   \n",
       "1         1       1  female      1      0  71.2833  First  woman       False   \n",
       "2         1       3  female      0      0   7.9250  Third  woman       False   \n",
       "3         1       1  female      1      0  53.1000  First  woman       False   \n",
       "4         0       3    male      0      0   8.0500  Third    man        True   \n",
       "\n",
       "  alive  alone  \n",
       "0    no  False  \n",
       "1   yes  False  \n",
       "2   yes   True  \n",
       "3   yes  False  \n",
       "4    no   True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree example\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/titanic.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e38e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult_male</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult_male  alone  sex_female  sex_male  class_First  class_Second  \\\n",
       "0           1      0           0         1            0             0   \n",
       "1           0      0           1         0            1             0   \n",
       "2           0      1           1         0            0             0   \n",
       "3           0      0           1         0            1             0   \n",
       "4           1      1           0         1            0             0   \n",
       "\n",
       "   class_Third  pclass     fare  sibsp  parch  \n",
       "0            1       3   7.2500      1      0  \n",
       "1            0       1  71.2833      1      0  \n",
       "2            1       3   7.9250      0      0  \n",
       "3            0       1  53.1000      1      0  \n",
       "4            1       3   8.0500      0      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.get_dummies(df[['sex', 'class', 'adult_male', 'alone']]).replace({False: 0, True:1})\n",
    "temp = pd.concat([temp, df[['pclass', 'fare', 'sibsp', 'parch']]], axis=1)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f7edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [3, 5, 10, 20], 'min_samples_leaf': [0.005, 0.01, 0.05, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "maxdepth = [3,5,10,20]\n",
    "minsampleleafs = [0.005 ,0.01, 0.05, 0.10]\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "hyperparameters = {'criterion': criterion,\n",
    "                   'max_depth': maxdepth,\n",
    "                   'min_samples_leaf':minsampleleafs\n",
    "                  }\n",
    "\n",
    "y = df.survived\n",
    "X = temp.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gsearch = GridSearchCV(model, hyperparameters, verbose=1)\n",
    "gsearch.fit(X_train, y_train, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b73197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_leaf': 0.05}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b757d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208955223880597"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = gsearch.best_estimator_.fit(X_train, y_train)\n",
    "accuracy_score(y_test, mod.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf2191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[140  17]\n",
      " [ 31  80]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2380c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       157\n",
      "           1       0.82      0.72      0.77       111\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       268\n",
      "   macro avg       0.82      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7937c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86d8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 512 candidates, totalling 1536 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1536 out of 1536 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 20, 50, 100], 'max_features': [2, 3, 5, 11], 'criterion': ['gini', 'entropy'], 'max_depth': [3, 5, 10, 20], 'min_samples_leaf': [0.005, 0.01, 0.05, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "nestimators = [10,20,50,100]\n",
    "criterion = ['gini', 'entropy']\n",
    "maxdepth = [3,5,10,20]\n",
    "minsampleleafs = [0.005 ,0.01, 0.05, 0.10]\n",
    "maxfeatures = [2,3,5,11]\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "hyperparameters = {'n_estimators': nestimators,\n",
    "                   'max_features': maxfeatures,\n",
    "                   'criterion': criterion,\n",
    "                   'max_depth': maxdepth,\n",
    "                   'min_samples_leaf':minsampleleafs\n",
    "                  }\n",
    "\n",
    "y = df.survived\n",
    "X = temp.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gsearch = GridSearchCV(model, hyperparameters, verbose=1)\n",
    "gsearch.fit(X_train, y_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4693bee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208955223880597"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = gsearch.best_estimator_.fit(X_train, y_train)\n",
    "accuracy_score(y_test, mod.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a28837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  16]\n",
      " [ 32  79]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb300452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.85       157\n",
      "           1       0.83      0.71      0.77       111\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       268\n",
      "   macro avg       0.82      0.80      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5004db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
